{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "ab1c2c9b-2448-4dde-cae7-965278b3a49e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygit2==1.15.1\n",
            "  Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pygit2==1.15.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.16.0->pygit2==1.15.1) (2.22)\n",
            "Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygit2\n",
            "  Attempting uninstall: pygit2\n",
            "    Found existing installation: pygit2 1.18.0\n",
            "    Uninstalling pygit2-1.18.0:\n",
            "      Successfully uninstalled pygit2-1.18.0\n",
            "Successfully installed pygit2-1.15.1\n",
            "/content\n",
            "Cloning into 'Fooocus'...\n",
            "remote: Enumerating objects: 6725, done.\u001b[K\n",
            "remote: Total 6725 (delta 0), reused 0 (delta 0), pack-reused 6725 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6725/6725), 33.33 MiB | 33.27 MiB/s, done.\n",
            "Resolving deltas: 100% (3856/3856), done.\n",
            "/content/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "Python 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 11.2MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 8.96MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v4.0.safetensors\n",
            "\n",
            "100% 5.40M/5.40M [00:00<00:00, 91.0MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:01<00:00, 323MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:41<00:00, 169MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 271MB/s]\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "Running on public URL: https://92938bb8b29825ef0b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "2025-05-25 20:21:47.082264: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748204507.332813    1614 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748204507.406904    1614 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-25 20:21:47.930041: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Started worker with PID 586\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://92938bb8b29825ef0b.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5445334007994748241\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/clip_vision_vit_h.safetensors\" to /content/Fooocus/models/clip_vision/clip_vision_vit_h.safetensors\n",
            "\n",
            "100% 1.84G/1.84G [00:13<00:00, 147MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_ip_negative.safetensors\" to /content/Fooocus/models/controlnet/fooocus_ip_negative.safetensors\n",
            "\n",
            "100% 64.1k/64.1k [00:00<00:00, 5.70MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/ip-adapter-plus_sdxl_vit-h.bin\" to /content/Fooocus/models/controlnet/ip-adapter-plus_sdxl_vit-h.bin\n",
            "\n",
            "100% 967M/967M [00:04<00:00, 214MB/s]\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A Full-Length shot of a female model in a standing upright pose, against a light gray background, wearing a knee-length button-down dress made of denim fabric. The dress has elbow-length sleeves, a collar, and a belt tied at the waist. The model has straight, dark hair parted in the center, and she is wearing large white statement earrings. She is wearing casual white sneakers. Her hands are by her sides, and her posture is relaxed with a neutral facial expression, solid focus, consistent, cinematic color, dramatic atmosphere, radiant colors, intricate, rich deep vivid colorful, extremely detailed, pretty, attractive, brave, smart, confident, passionate, beautiful, delicate, very creative, elegant,, surreal, highly\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A Full-Length shot of a female model in a standing upright pose, against a light gray background, wearing a knee-length button-down dress made of denim fabric. The dress has elbow-length sleeves, a collar, and a belt tied at the waist. The model has straight, dark hair parted in the center, and she is wearing large white statement earrings. She is wearing casual white sneakers. Her hands are by her sides, and her posture is relaxed with a neutral facial expression, solid focus, vivid color, highly detailed, cinematic, stunning, sublime, creative, romantic, epic, positive, shiny, attractive, pretty, agile, passionate, cool, intricate, extremely aesthetic, smart, very inspirational, inspired, beautiful\n",
            "[Fooocus] Preparing Fooocus text #3 ...\n",
            "[Prompt Expansion] A Full-Length shot of a female model in a standing upright pose, against a light gray background, wearing a knee-length button-down dress made of denim fabric. The dress has elbow-length sleeves, a collar, and a belt tied at the waist. The model has straight, dark hair parted in the center, and she is wearing large white statement earrings. She is wearing casual white sneakers. Her hands are by her sides, and her posture is relaxed with a neutral facial expression, bright vibrant colors, ambient, dramatic cinematic, expressive dynamic, sharp focus, intricate, very inspirational, stunning, creative, attractive, innocent, beautiful, confident, romantic, symmetry, highly detailed, pretty, inspired, color spread, clear, crisp\n",
            "[Fooocus] Preparing Fooocus text #4 ...\n",
            "[Prompt Expansion] A Full-Length shot of a female model in a standing upright pose, against a light gray background, wearing a knee-length button-down dress made of denim fabric. The dress has elbow-length sleeves, a collar, and a belt tied at the waist. The model has straight, dark hair parted in the center, and she is wearing large white statement earrings. She is wearing casual white sneakers. Her hands are by her sides, and her posture is relaxed with a neutral facial expression, solid colors, romantic, expressive, beautiful detailed intricate, cool color, amazing detail, creative, inspirational, elegant, vibrant, attractive, dramatic cinematic, very aesthetic, inspired, fine, extremely artistic, best, dynamic, illuminated, deep vivid\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.21 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.89 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 29.36 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/4 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.24 seconds\n",
            "100% 60/60 [00:54<00:00,  1.11it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "[Fooocus] Saving image 1/4 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 58.20 seconds\n",
            "[Fooocus] Preparing task 2/4 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            " 23% 14/60 [00:13<00:44,  1.03it/s]\n",
            "User skipped\n",
            "[Fooocus] Preparing task 3/4 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "  7% 4/60 [00:04<01:03,  1.13s/it]\n",
            "User skipped\n",
            "[Fooocus] Preparing task 4/4 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "  5% 3/60 [00:03<01:09,  1.21s/it]\n",
            "User skipped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 80.77 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 110.20 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.93 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6593826086373882416\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A male model in a standing upright pose, against a light gray background, beautiful full detailed intricate colorful, cinematic, stunning, highly detail, creative, rich bright colors, epic, perfect composition, clear, coherent, strong, best, artistic, new, great, aesthetic, awesome, inspired, cute, ambient, vibrant, color, intense, complex, amazing, symmetry\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A male model in a standing upright pose, against a light gray background, dramatic deep focus, intricate, elegant, highly detailed, extremely professional, colorful, open color, original composition, great classic fine detail, sharp, still, dynamic, strong vivid colors, inspired, ambient aesthetic, shiny, rich, epic, stunning, gorgeous, awesome, cinematic, symmetry, artistic\n",
            "[Fooocus] Preparing Fooocus text #3 ...\n",
            "[Prompt Expansion] A male model in a standing upright pose, against a light gray background, dramatic deep focus, dynamic composition, intricate, elegant, highly detailed, very inspirational, innocent, fine detail, full color, sharp, beautiful, cinematic, artistic, complex, vibrant colors, symmetry, inspired, new, shiny, colorful, glowing, epic, rich, grand, scenic, thought\n",
            "[Fooocus] Preparing Fooocus text #4 ...\n",
            "[Prompt Expansion] A male model in a standing upright pose, against a light gray background, detailed, artistic composition, dramatic, deep focus, beautiful, intricate, elegant, highly detail, incredible quality, sharp, perfect, colorful, rational, attractive, best, atmosphere, professional, bright colors, great, fine, complex, iconic, imposing, clear, very aesthetic, amazing, symmetry\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.20 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.49 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 6.33 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/4 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.67 seconds\n",
            "100% 60/60 [00:52<00:00,  1.13it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "[Fooocus] Saving image 1/4 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 56.34 seconds\n",
            "[Fooocus] Preparing task 2/4 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.66 seconds\n",
            "100% 60/60 [00:54<00:00,  1.10it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 2/4 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 57.88 seconds\n",
            "[Fooocus] Preparing task 3/4 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "100% 60/60 [00:55<00:00,  1.08it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 3/4 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 58.76 seconds\n",
            "[Fooocus] Preparing task 4/4 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "100% 60/60 [00:56<00:00,  1.07it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 4/4 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 59.57 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 232.55 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 238.94 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.89 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7b14f8093880>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6593826086373882416\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 422, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 1.03 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7b17a65e6cf0>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6593826086373882416\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 422, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 1.08 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7b14f8074540>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6593826086373882416\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 422, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 1.13 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 1161050722919507959\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A baby girl model in a standing upright pose, gorgeous, intricate, elegant, highly detailed, focus, candid, dramatic, bright, dynamic, thought, magic, clear, crisp, sharp, excellent composition, innocent, expressive, strong detail, aesthetic, very inspirational, shiny, glowing, colorful, epic, stunning, brave, awarded, creative, pure, passionate, beautiful\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A baby girl model in a standing upright pose, beautiful highly detailed perfect light, very delicate intricate, stunning gentle, inspiring, charming, cute, enhanced, background inspired, vibrant color, illuminated, epic composition, complex, elegant, amazing colors, peaceful, scenic, rich deep aesthetic, thought, iconic, sharp focus, creative, winning, cinematic, extremely attractive, pretty\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.21 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 4.53 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.68 seconds\n",
            "100% 60/60 [00:51<00:00,  1.16it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 55.16 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            " 23% 14/60 [00:13<00:43,  1.06it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 69.01 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 4298196552582172097\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A baby girl model is standing upright pose, intricate, elegant, highly detailed, clear focus, candid, very pretty, inspired, innocent, beautiful, pure, attractive, delicate, artistic, inspiring, cute, fine detail, full color, iconic, scenic background, dramatic light, amazing, illuminated, true, inspirational, vibrant, best, real, quality, silent, shining\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A baby girl model is standing upright pose, intricate, elegant, highly detailed, clear focus, candid, cute, divine, expressive, flowing, loving, pretty, mystical, dramatic, lucid, thought, cinematic, complex, very inspirational, colorful, sharp, fine detail, enhanced, epic, inspiring, attractive, artistic, marvelous, positive, cheerful, hopeful, unique\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 2.41 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.24 seconds\n",
            "100% 30/30 [00:25<00:00,  1.17it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 29.68 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.66 seconds\n",
            "100% 30/30 [00:26<00:00,  1.15it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 29.37 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 59.04 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 61.51 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 7090286904010303763\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A baby girl model is standing upright pose, intricate, elegant, highly detailed, clear focus, candid, beautiful, inspired, handsome, presented, full color, bright, vivid, attractive, pretty, true scientific, holy, spiritual, trendy, best, pure, light, atmosphere, cheerful, dramatic, illuminated, infinite, loving, perfect, creative, positive, hopeful\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A baby girl model is standing upright pose, beautiful detailed intricate stunning fine detail, gentle light, relaxed atmosphere, perfect calm cinematic dramatic background, vivid vibrant attractive colors, inspired very highly complex, delicate, elegant, epic composition, professional color, best, awesome creative, cheerful, cute, exotic, iconic, cool, magical, mystical, thought, marvelous, fancy, gorgeous\n",
            "[Fooocus] Preparing Fooocus text #3 ...\n",
            "[Prompt Expansion] A baby girl model is standing upright pose, complex artistic color, background, detailed, elegant, intricate, highly colorful, vibrant, sharp focus, dramatic light, beautiful, advanced, enhanced quality, bright colors, inspired, illustrious, fine detail, creative, winning contemporary novel, best, gorgeous, modern, romantic, confident, pretty, perfect, sleek, amazing, awesome\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.20 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.48 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1216, 832)\n",
            "Preparation time: 5.28 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.67 seconds\n",
            "100% 60/60 [00:51<00:00,  1.16it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Fooocus] Saving image 1/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 55.12 seconds\n",
            "[Fooocus] Preparing task 2/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.68 seconds\n",
            "100% 60/60 [00:53<00:00,  1.12it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 2/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 56.91 seconds\n",
            "[Fooocus] Preparing task 3/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "100% 60/60 [00:54<00:00,  1.10it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 3/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 57.75 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 169.77 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 175.11 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.87 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 1677290598303265221\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Gate dress in the first image, select the model's face from the second image, cinematic light, scenic, artistic, fine detail, perfect, intricate, sharp focus, elegant, confident, color set, great composition, detailed, attractive, smart, illustrious, beautiful, advanced, elite, dramatic ambient background, professional, modern, futuristic, best, creative, positive, thoughtful\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Gate dress in the first image, select the model's face from the second image, cinematic light, dramatic background, scenic, professional, detailed, sharp focus, fair quality, perfect, very attractive, extremely detail, cool colors, intricate, elegant, epic, highly color balanced, artistic, innocent, pure, determined, beautiful, inspired, vibrant, complex, joyful, passionate\n",
            "[Fooocus] Preparing Fooocus text #3 ...\n",
            "[Prompt Expansion] Gate dress in the first image, select the model's face from the second image, cinematic light, dramatic ambient, open cool flowing color, detailed, professional composition, elegant, beautiful, symmetry, creative, positive aesthetic, shiny, attractive, intricate, inspirational, pretty, calm, friendly, determined, generous, cute, cheerful, background, lovely, coherent, quality, full\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.20 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.48 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.55 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.42 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.22 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1216, 832)\n",
            "Preparation time: 6.83 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.64 seconds\n",
            "100% 60/60 [00:52<00:00,  1.15it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Fooocus] Saving image 1/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 55.62 seconds\n",
            "[Fooocus] Preparing task 2/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.65 seconds\n",
            " 38% 23/60 [00:21<00:34,  1.06it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 77.90 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 84.79 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.82 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5623536901353773359\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Gate dress in the first image, select the model's face from the second image, cinematic light, dramatic background, ambient, professional, highly detailed, sharp focus, elegant, intricate, clear, artistic color, perfect composition, innocent, beautiful, symmetry, stunning, pretty, inspired, rich deep colors, aesthetic, great, full detail, very inspirational, moving, creative\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Gate dress in the first image, select the model's face from the second image, cinematic light, sharp focus, intricate, elegant, highly detailed, rich deep colors, excellent composition, dynamic dramatic colorful futuristic atmosphere, aesthetic, very inspirational, bright color, open background, creative, cute, perfect romantic, expressive, innocent, pretty, attractive, brave, vibrant, inspired\n",
            "[Fooocus] Preparing Fooocus text #3 ...\n",
            "[Prompt Expansion] Gate dress in the first image, select the model's face from the second image, cinematic light, background dramatic ambient composition, detailed, elegant, intricate, highly saturated colors, sharp focus, inspired, stunning new, great inspirational, gorgeous, creative, positive, attractive, beautiful, relaxed, cute, fine detail, full color, amazing, perfect, colorful, balance, symmetry\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.14 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.54 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.41 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.22 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1216, 832)\n",
            "Preparation time: 6.11 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.63 seconds\n",
            "100% 60/60 [00:54<00:00,  1.11it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 57.49 seconds\n",
            "[Fooocus] Preparing task 2/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "100% 60/60 [00:55<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.32 seconds\n",
            "[Fooocus] Saving image 2/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 58.42 seconds\n",
            "[Fooocus] Preparing task 3/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "100% 60/60 [00:55<00:00,  1.07it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 3/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 59.35 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 175.26 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 181.45 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.98 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 4250841249103879626\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Gate t-shirt in the first image, select the model's face from the second image, bright colors, advanced color, cinematic, light shining, intricate, elegant, sharp focus, professional composition, highly detailed, colorful, epic, stunning, romantic, scenic, best detail, clear, peaceful, beautiful, modern, futuristic background, ambient, dynamic, thought, perfect\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Gate t-shirt in the first image, select the model's face from the second image, bright colors, aesthetic inspired, illustrious deep intricate detailed, sharp focus, cinematic light, excellent composition, dynamic dramatic atmosphere, highly detail, appealing, rich vibrant color, beautiful epic surreal futuristic background, professional fine scenic, ambient, creative, winning awarded, best artistic, cool, perfect\n",
            "[Fooocus] Preparing Fooocus text #3 ...\n",
            "[Prompt Expansion] Gate t-shirt in the first image, select the model's face from the second image, cinematic light, scenic background, sharp focus, elegant, highly detailed, very professional fine detail, real full color, attractive, intricate, innocent, sweet, perfect, pretty, cheerful, artistic, pure, confident, rational, dramatic ambient composition, whole atmosphere, great quality, creative\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.18 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1216, 832)\n",
            "Preparation time: 6.46 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.68 seconds\n",
            "100% 60/60 [00:53<00:00,  1.12it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 56.85 seconds\n",
            "[Fooocus] Preparing task 2/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.62 seconds\n",
            " 23% 14/60 [00:13<00:45,  1.02it/s]\n",
            "User skipped\n",
            "[Fooocus] Preparing task 3/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "  8% 5/60 [00:05<01:00,  1.10s/it]\n",
            "User skipped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 76.69 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 83.20 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 729535629448106071\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Gate dress in the first image, select the model's face from the second image, cinematic, background dramatic light, scenic, warm colors, calm, vivid, detailed, focus, extremely detail, beautiful, intricate, innocent, symmetry, great composition, elegant, perfect, novel, romantic, full, thought, ambient, professional, highly coherent, color, epic, clear\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Gate dress in the first image, select the model's face from the second image, cinematic light, dramatic background, scenic, warm colors, calm, sharp focus, extremely detailed, beautiful, intricate, innocent, symmetry, inspired, fine colorful, epic, great composition, professional, winning, vivid, awesome color, ambient, dynamic, elegant, very inspirational, rich deep aesthetic\n",
            "[Fooocus] Preparing Fooocus text #3 ...\n",
            "[Prompt Expansion] Gate dress in the first image, select the model's face from the second image, cinematic, focus, dramatic light, detailed, deep, rich colors, creative, fair composition, elegant, perfect intricate, stunning, highly advanced, professional, futuristic, best, romantic, iconic, modern, cool, cute, great, atmosphere, new, color, awesome, classic, full\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.15 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.49 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.54 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.41 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.22 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1216, 832)\n",
            "Preparation time: 6.67 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.63 seconds\n",
            " 12% 7/60 [00:07<00:54,  1.03s/it]\n",
            "User skipped\n",
            "[Fooocus] Preparing task 2/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "  8% 5/60 [00:05<00:58,  1.07s/it]\n",
            "User skipped\n",
            "[Fooocus] Preparing task 3/3 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "100% 60/60 [00:54<00:00,  1.11it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "[Fooocus] Saving image 3/3 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-25/log.html\n",
            "Generating and saving time: 56.89 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 70.09 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n"
          ]
        }
      ],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}